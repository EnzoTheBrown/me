name: Sync repository to public S3 bucket

on:
  push:
    branches: [ "main" ]
  workflow_dispatch: {}

permissions:
  contents: write

jobs:
  sync:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      # Optional: if you want to exclude stuff like .git, workflow files, etc.
      - name: Sync repo to S3 (mirror)
        run: |
          aws s3 sync . "s3://${{ secrets.S3_BUCKET }}/" \
            --delete \
            --exact-timestamps \
            --exclude ".git/*" \
            --exclude ".github/*" \
            --exclude "node_modules/*" \
            --exclude ".DS_Store" \
            --exclude "**/.DS_Store" \
            --exclude "scripts" \
            --acl public-read

      # If you need correct content-types for web serving, you can optionally add metadata rules.
      # Usually S3 will infer some types; for strict control you'd do per-extension uploads or CloudFront.

      - name: Generate index.json
        run: |
          python scripts/generate_index.py

      - name: Commit index.json if changed
        run: |
          if git status --porcelain index.json | grep .; then
            git config user.name "github-actions"
            git config user.email "github-actions@github.com"
            git add index.json
            git commit -m "chore: update index.json"
            git push
          else
            echo "index.json unchanged, nothing to commit"
          fi
